spring:
  kafka:
    consumer:
      # 关闭自动提交offset
      enable-auto-commit: false
      # 设置offset开始位置
      # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新该分区下产生的数据
      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: ${INV_KAFKA_AUTO_OFFSET_RESET:earliest}
      # kafka集群地址
      bootstrap-servers: ${INV_KAFKA_CLUSTER:[192.168.0.11,192.168.0.12,192.168.0.13]}
      # 消费者组id
      group-id: inventory
      # 心跳检测时间，默认3s
      heartbeat-interval: ${INV_KAFKA_HEARTBEAT_INTERVAL:3000ms}
      # 最大拉取数据条数
      max-poll-records: ${INV_CONSUMER_MAX_POLL_RECORDS:100}
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        # 会话时间超过(服务宕机),节点将从消费者组中移除,数据重平衡,默认10s
        session:
          timeout:
            ms: ${INV_KAFKA_SESSION_TIMEOUT:10000ms}
        # 服务消费超时,将进行数据重平衡,默认5分钟
        max:
          poll:
            interval:
              ms: ${INV_KAFAK_MAX_POLL_INTERVAL:300000ms}
        fetch:
          max:
            # 每次拉取最大数据量,默认50m
            bytes: ${INV_KAFKA_FETCH_MAX_BYTES:50*1024*1024}
            # 每次拉取数据等待最大时间,默认500ms
            wait:
              ms: ${INV_KAFKA_FETCH_MAX_WAIT:500}
          # 每次拉取最小数据量,默认1b
          min:
            bytes: ${INV_KAFKA_FETCH_MIN_BYTES:1}
    listener:
      # 处理ConsumerRecord模式，可以分为single(单条)和batch(批次)两种方式
      type: single
      # 在关闭自动提交offset模式时,设置ackMode来决定在那个环节手动提交offset
      # record:
      # batch:
      # time:
      # count:
      # count_time:
      # manual:
      # manual_immediate:
      ack-mode: manual_immediate
      # 消费者拉取数据超时时间，默认5s
      poll-timeout: ${INV_CONSUMER_POLL_TIMEOUT:5000ms}